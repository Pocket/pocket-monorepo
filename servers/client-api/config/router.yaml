sandbox:
  enabled: false
supergraph:
  introspection: true
  listen: 0.0.0.0:${env.PORT:-4001}
  query_planning:
    cache:
      redis:
        urls: ['${env.REDIS_PROTOCOL:-rediss-cluster}://${env.REDIS_ENDPOINT}']
        ttl: 48h # optional, by default no expiration
include_subgraph_errors:
  all: true # Propagate errors from all subgraphs
health_check:
  listen: 0.0.0.0:${env.PORT}
  enabled: true
  path: /.well-known/apollo/server-health
limits:
  parser_max_tokens: 15000 # This is the default value.
  parser_max_recursion: 4096 # This is the default value.
  max_depth: 100 # Must be 15 or larger to support standard introspection query
  max_height: 225
  max_aliases: 30
  max_root_fields: 30

traffic_shaping:
  all:
    ### Note: Recs api does not support gzip compression as of 10/16/2024, so this can not be turned on.
    # compression: gzip # Enable gzip compression for all subgraphs.

    # We enable experimental retry for all subgraphs because our parser can cause things to fail the first time and succeed the second time.
    # Also, it doesn't hurt to have this enabled for all subgraphs, just adds latency for any requests that may fail.
    experimental_retry:
      min_per_sec: 10 # minimal number of retries per second (`min_per_sec`, default is 10 retries per second)
      ttl: 10s # for each successful request, we register a token, that expires according to this option (default: 10s)
      retry_percent: 0.2 # defines the proportion of available retries to the current number of tokens
      retry_mutations: false # allows retries on mutations. This should only be enabled if mutations are idempotent

authentication:
  router:
    jwt:
      jwks:
        - url: https://getpocket.com/.well-known/jwk
authorization:
  require_authentication: false
  # We allow clients to request and get some things as unauthorized
  # https://www.apollographql.com/docs/graphos/routing/security/authorization#log
  directives:
    errors:
      log: false
rhai:
  scripts: './rhai'
  main: 'main.rhai'
headers:
  all:
    request:
      # Note: Additional JWT headers and headers which need special processing
      # are handled in Rhai scripts
      - propagate:
          named: 'web-request-langugage'
          rename: 'gatewayLanguage'
      - propagate:
          named: 'web-request-ip-address'
          rename: 'gatewayIpAddress'
      - propagate:
          named: 'web-request-snowplow-domain-user-id'
          rename: 'gatewaySnowplowDomainUserId'
      - propagate:
          named: 'web-request-user-agent'
          rename: 'gatwayUserAgent'
      - propagate:
          named: 'transfersub'
      - propagate:
          named: 'web-request-snowplow-session-user-id'
          rename: 'gatewaySnowplowDomainSessionId'
demand_control:
  enabled: false
  mode: measure
  strategy:
    static_estimated:
      list_size: 10
      max: 1000
telemetry:
  instrumentation:
    instruments:
      # https://www.apollographql.com/docs/graphos/reference/router/telemetry/instrumentation/instruments#default_requirement_level
      default_requirement_level: recommended
      router:
        http.server.active_requests: true
        http.server.request.body.size:
          attributes:
            'http.request.header.apollographql-client-name':
              request_header: 'apollographql-client-name'
            'http.request.header.apollographql-client-version':
              request_header: 'apollographql-client-version'
        http.server.request.duration:
          attributes:
            http.response.status_code: true
            'http.request.header.apollographql-client-name':
              request_header: 'apollographql-client-name'
            'http.request.header.apollographql-client-version':
              request_header: 'apollographql-client-version'
            'graphql.operation.name': # Will set this attribute with the operation name
              operation_name: string
            'graphql.errors': # Will set this attribute to true if it contains graphql error (includes unauthorized)
              on_graphql_error: true
            'graphql.critical.error':
              error: reason
      subgraph:
        http.client.request.body.size:
          attributes:
            'subgraph.graphql.document': false
        http.client.request.duration:
          attributes:
            'subgraph.graphql.document': false
        http.client.response.body.size:
          attributes:
            'subgraph.graphql.document': false
      # Costs are from https://www.apollographql.com/docs/graphos/routing/security/demand-control#examples
      supergraph:
        cost.estimated:
          attributes:
            cost.result: true
            graphql.operation.name: true
        cost.rejected.operations:
          type: histogram
          value:
            # Estimated cost is used to populate the histogram
            cost: estimated
          description: 'Estimated cost per rejected operation.'
          unit: delta
          condition:
            eq:
              # Only show rejected operations.
              - cost: result
              - 'COST_ESTIMATED_TOO_EXPENSIVE'
          attributes:
            graphql.operation.name: true # Graphql operation name is added as an attribute
    events:
      supergraph:
        COST_DELTA_TOO_HIGH:
          message: 'cost delta high'
          on: event_response
          level: error
          condition:
            gt:
              - cost: delta
              - 1000
          attributes:
            graphql.operation.name: true
            cost.delta: true
    spans:
      mode: spec_compliant
      supergraph:
        attributes:
          cost.estimated: true
      router:
        attributes:
          'http.request.header.apollographql-client-name':
            request_header: 'apollographql-client-name'
          'http.request.header.apollographql-client-version':
            request_header: 'apollographql-client-version'

  apollo:
    send_variable_values:
      only:
        - filters # getCollections
        - page # getCollections
        - perPage # getCollections
        - slug # collectionBySlug
  exporters:
    logging:
      common:
        resource:
          'environment.name': '${env.APP_ENVIRONMENT}'
          'service.name': 'client-api'
          'environment.namespace': pocket
          'cloud.provider': '${env.CLOUD_PROVIDER}'
          'cloud.platform': '${env.CLOUD_PLATFORM}'
          'container.name': '${env.CONTAINER_NAME}'
          'container.id': '${env.CONTAINER_ID}'
          'aws.ecs.container.arn': '${env.AWS_ECS_CONTAINER_ARN}'
          'aws.ecs.cluster.arn': '${env.AWS_ECS_CLUSTER_ARN}'
          'aws.ecs.launchtype': '${env.AWS_ECS_LAUNCHTYPE}'
          'aws.ecs.task.arn': '${env.AWS_ECS_TASK_ARN}'
          'aws.ecs.task.family': '${env.AWS_ECS_TASK_FAMILY}'
          'aws.ecs.task.revision': '${env.AWS_ECS_TASK_REVISION}'
          'cloud.account_id': '${env.CLOUD_ACCOUNT_ID}'
          'cloud.region': '${env.CLOUD_REGION}'
          'cloud.resource_id': '${env.CLOUD_RESOURCE_ID}'
          'cloud.availability_zone': '${env.CLOUD_AVAILABILITY_ZONE}'
          'aws.log.group.names': '${env.AWS_LOG_GROUP_NAMES}'
          'aws.log.group.arns': '${env.AWS_LOG_GROUP_ARNS}'
          'aws.log.stream.names': '${env.AWS_LOG_STREAM_NAMES}'
          'aws.log.stream.arns': '${env.AWS_LOG_STREAM_ARNS}'
          'host.name': '${env.CONTAINER_NAME}'

    metrics:
      common:
        resource:
          'environment.name': '${env.APP_ENVIRONMENT}'
          'service.name': 'client-api'
          'environment.namespace': pocket
          'cloud.provider': '${env.CLOUD_PROVIDER}'
          'cloud.platform': '${env.CLOUD_PLATFORM}'
          'container.name': '${env.CONTAINER_NAME}'
          'container.id': '${env.CONTAINER_ID}'
          'aws.ecs.container.arn': '${env.AWS_ECS_CONTAINER_ARN}'
          'aws.ecs.cluster.arn': '${env.AWS_ECS_CLUSTER_ARN}'
          'aws.ecs.launchtype': '${env.AWS_ECS_LAUNCHTYPE}'
          'aws.ecs.task.arn': '${env.AWS_ECS_TASK_ARN}'
          'aws.ecs.task.family': '${env.AWS_ECS_TASK_FAMILY}'
          'aws.ecs.task.revision': '${env.AWS_ECS_TASK_REVISION}'
          'cloud.account_id': '${env.CLOUD_ACCOUNT_ID}'
          'cloud.region': '${env.CLOUD_REGION}'
          'cloud.resource_id': '${env.CLOUD_RESOURCE_ID}'
          'cloud.availability_zone': '${env.CLOUD_AVAILABILITY_ZONE}'
          'aws.log.group.names': '${env.AWS_LOG_GROUP_NAMES}'
          'aws.log.group.arns': '${env.AWS_LOG_GROUP_ARNS}'
          'aws.log.stream.names': '${env.AWS_LOG_STREAM_NAMES}'
          'aws.log.stream.arns': '${env.AWS_LOG_STREAM_ARNS}'
          'host.name': '${env.CONTAINER_NAME}'

        views:
          # https://www.apollographql.com/docs/graphos/routing/security/demand-control#configuring-instrument-output
          # Define a custom view because cost is different than the default latency-oriented view of OpenTelemetry
          - name: cost.*
            aggregation:
              histogram:
                buckets:
                  - 0
                  - 10
                  - 100
                  - 1000
                  - 10000
                  - 100000
                  - 1000000
      otlp:
        enabled: true
        endpoint: '${env.OTLP_COLLECTOR_URL:-http://localhost:4318}/v1/metrics'
        protocol: http
        batch_processor:
          scheduled_delay: 10000ms # 10 secs export due to google cloud rate limits
          max_concurrent_exports: 1000
          max_export_batch_size: 10000
          max_export_timeout: 100s
          max_queue_size: 10000
    tracing:
      common:
        resource:
          'environment.name': '${env.APP_ENVIRONMENT}'
          'service.name': 'client-api'
          'environment.namespace': pocket
          'cloud.provider': '${env.CLOUD_PROVIDER}'
          'cloud.platform': '${env.CLOUD_PLATFORM}'
          'container.name': '${env.CONTAINER_NAME}'
          'container.id': '${env.CONTAINER_ID}'
          'aws.ecs.container.arn': '${env.AWS_ECS_CONTAINER_ARN}'
          'aws.ecs.cluster.arn': '${env.AWS_ECS_CLUSTER_ARN}'
          'aws.ecs.launchtype': '${env.AWS_ECS_LAUNCHTYPE}'
          'aws.ecs.task.arn': '${env.AWS_ECS_TASK_ARN}'
          'aws.ecs.task.family': '${env.AWS_ECS_TASK_FAMILY}'
          'aws.ecs.task.revision': '${env.AWS_ECS_TASK_REVISION}'
          'cloud.account_id': '${env.CLOUD_ACCOUNT_ID}'
          'cloud.region': '${env.CLOUD_REGION}'
          'cloud.resource_id': '${env.CLOUD_RESOURCE_ID}'
          'cloud.availability_zone': '${env.CLOUD_AVAILABILITY_ZONE}'
          'aws.log.group.names': '${env.AWS_LOG_GROUP_NAMES}'
          'aws.log.group.arns': '${env.AWS_LOG_GROUP_ARNS}'
          'aws.log.stream.names': '${env.AWS_LOG_STREAM_NAMES}'
          'aws.log.stream.arns': '${env.AWS_LOG_STREAM_ARNS}'
          'host.name': '${env.CONTAINER_NAME}'
        sampler: 0.01 # (default) all requests are sampled (always_on|always_off|<0.0-1.0>)
        parent_based_sampler: true
      propagation:
        aws_xray: true

      experimental_response_trace_id:
        enabled: true
        header_name: 'pocket-trace-id'
      otlp:
        enabled: true
        endpoint: '${env.OTLP_COLLECTOR_URL:-http://localhost:4318}'
        protocol: http
        batch_processor:
          scheduled_delay: 100ms
          max_concurrent_exports: 1000
          max_export_batch_size: 10000
          max_export_timeout: 2s
          max_queue_size: 10000
apq:
  router:
    cache:
      redis:
        urls: ['${env.REDIS_PROTOCOL:-rediss-cluster}://${env.REDIS_ENDPOINT}']
        ttl: 24h # optional, by default no expiration
coprocessor:
  url: '${env.COPROCESSOR_URL:-http://localhost:3007}'
  timeout: 100s # The timeout for all coprocessor requests. Defaults to 1 second (1s)
  router: # This coprocessor hooks into the `RouterService`
    request: # By including this key, the `RouterService` sends a coprocessor request whenever it first receives a client request.
      headers: true # These boolean properties indicate which request data to include in the coprocessor request. All are optional and false by default.
      body: true
      context: true
      sdl: false
      path: true
      method: false
